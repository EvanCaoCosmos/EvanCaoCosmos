<p>1.在transformer的位置编码中，relative position和absolute position有什么区别
2024/1/8 15:36:45
在transformer的位置编码中，relative position和absolute position的区别如下：
•	Absolute Position: 绝对位置编码是指将每个输入位置映射到一个固定的位置向量上。这意味着每个位置的编码都是确定的，不会随着输入序列的变化而改变。
•	Relative Position: 相对位置编码是指根据输入序列中元素之间的相对距离动态计算位置编码。这种编码方式允许模型更好地捕捉输入序列中元素之间的相对关系，而不受输入序列长度的影响。相对位置编码通常通过一些特定的机制，比如attention机制中的相对位置注意力来实现。
总的来说，绝对位置编码是固定的，而相对位置编码是根据输入序列内部元素之间的相对关系动态计算的。两者分别适用于不同的应用场景和模型结构设计。
2024/1/8 16:00:58</p>
<p>2.为什么feed forward要由两个全连接层组成
2024/1/8 16:01:18
Feed forward层由两个全连接层组成的主要原因是为了增加模型的表达能力和非线性建模能力。
第一个全连接层通常会将输入数据映射到一个更高维度的空间，在这个高维空间中进行一些非线性变换。然后通过激活函数引入非线性，使得模型可以学习复杂的特征表示。
接着，第二个完全连接层将上一层的输出映射回原始的低维空间，进行进一步的特征提取和非线性变换。这种结构允许模型学习更复杂的特征和关系，同时也增加了模型的拟合能力。
总的来说，通过使用两个全连接层，feed forward层可以更好地捕获输入特征之间的复杂关系，并且增加了模型的非线性建模能力，从而提高了模型的表达能力和性能。
2024/1/8 16:02:27</p>
<p>3.那么为什么第二个全连接层不加激活函数
2024/1/8 16:02:53
第二个全连接层通常不加激活函数的原因是为了保留一定的线性特性，从而使得模型能够学习到更加灵活的表示。
当我们在前面的全连接层中引入了非线性激活函数（如ReLU、tanh等）时，模型就会学习到较为复杂的非线性变换和特征表示。然而，在接下来的全连接层中不加入激活函数，可以让模型保留一些线性变换的能力，这对于某些任务可能是有益的。
另外一个原因是，加入激活函数会限制输出值的范围，而有时候我们希望输出值的范围不受限制，比如在某些回归任务中。因此，省略第二个全连接层的激活函数可以使模型具有更大的拟合能力，同时保持一定的线性特性。
总之，省略第二个全连接层的激活函数通常是出于保留一定线性特性以及增强模型表达能力的考虑。
</p>
2024/1/8 16:05:39
<p>4.部分resblock为什么会先把输入数据映射到一个更低维度的空间，而不是更高？
2024/1/8 16:07:31
部分残差块（part of a ResNet block）之所以先将输入数据映射到一个更低维度的空间，而不是更高，是出于对模型性能和训练效果的考虑。
其主要原因有以下几点：
1.	降低计算成本：通过将输入映射到较低维度的空间，可以降低后续的计算成本。这种降维操作有助于减少模型的参数数量和计算复杂度，同时提高训练和推理时的效率。
2.	增强特征提取：通过降维操作，可以增强特征提取的效果。在一些情况下，通过将输入映射到较低维度的空间，可以突出并捕获输入中最重要的特征，从而有助于提升模型的表达能力。
3.	缓解过拟合：降低输入维度也有助于减少模型的过拟合风险。通过减少每个残差块中的参数数量，可以降低模型的复杂度，缓解过拟合问题。
总的来说，部分残差块之所以会先将输入数据映射到一个更低维度的空间，是为了在保持模型性能的基础上，降低计算成本、增强特征提取效果，并缓解过拟合问题。</p>

